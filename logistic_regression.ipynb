{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Social_Network_Ads.csv')\n",
    "df['Gender'] = df['Gender'].replace({'Male': 0, 'Female': 1})\n",
    "X=df[['Gender','Age','EstimatedSalary']].values\n",
    "y = df[['Purchased']].values\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = ros.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.8224507787246548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zivad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "90 fits failed out of a total of 540.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\zivad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\zivad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\zivad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\zivad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\zivad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.51096092 0.51096092        nan 0.51096092 0.51096092 0.57681458\n",
      " 0.51096092 0.51096092        nan 0.51096092 0.51096092 0.57681458\n",
      " 0.51096092 0.51096092        nan 0.51096092 0.51096092 0.57681458\n",
      " 0.51096092 0.51096092        nan 0.51096092 0.51096092 0.57681458\n",
      " 0.51096092 0.51096092        nan 0.51096092 0.51096092 0.57681458\n",
      " 0.51096092 0.51096092        nan 0.51096092 0.51096092 0.57681458\n",
      " 0.81757273 0.51096092        nan 0.51096092 0.51096092 0.57681458\n",
      " 0.81998237 0.51096092        nan 0.51096092 0.51096092 0.57681458\n",
      " 0.82245078 0.51096092        nan 0.51096092 0.51096092 0.57681458\n",
      " 0.81769027 0.51096092        nan 0.51096092 0.51096092 0.57681458\n",
      " 0.8201293  0.51096092        nan 0.51096092 0.51096092 0.57681458\n",
      " 0.8201293  0.51096092        nan 0.51096092 0.51096092 0.57681458\n",
      " 0.8201293  0.51096092        nan 0.51096092 0.51096092 0.57681458\n",
      " 0.8201293  0.51096092        nan 0.51096092 0.51096092 0.57681458\n",
      " 0.8201293  0.51096092        nan 0.51096092 0.51096092 0.57681458\n",
      " 0.81769027 0.51096092        nan 0.51096092 0.51096092 0.57681458\n",
      " 0.81769027 0.51096092        nan 0.51096092 0.51096092 0.57681458\n",
      " 0.8201293  0.51096092        nan 0.51096092 0.51096092 0.57681458]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga', 'lbfgs'],\n",
    "    'max_iter': [100, 1000, 10000]\n",
    "}\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=parameters, scoring='accuracy', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_parameters = grid.best_params_\n",
    "best_score = grid.best_score_\n",
    "\n",
    "print(best_parameters)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88        56\n",
      "           1       0.83      0.91      0.87        47\n",
      "\n",
      "    accuracy                           0.87       103\n",
      "   macro avg       0.87      0.88      0.87       103\n",
      "weighted avg       0.88      0.87      0.87       103\n",
      "\n",
      "[[47  9]\n",
      " [ 4 43]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=0.1, max_iter=10000, penalty='l1', solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix (y_test, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
